name: Migrate GitHub Repository to S3

on:
  push:
    branches: [ main ]
  workflow_dispatch:  # Allows manual triggering

jobs:
  migrate-to-s3:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Fetch all history for all branches and tags
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'
    
    - name: Install AWS CLI
      run: |
        pip install awscli
    
    - name: Verify AWS credentials
      run: |
        echo "Checking if AWS credentials exist:"
        if [ -n "$AWS_ACCESS_KEY" ]; then
          echo "✅ AWS_ACCESS_KEY secret exists"
        else
          echo "❌ AWS_ACCESS_KEY secret is missing or empty"
          exit 1
        fi
        if [ -n "$AWS_SECRET_ACCESS_KEY" ]; then
          echo "✅ AWS_SECRET_ACCESS_KEY secret exists"
        else
          echo "❌ AWS_SECRET_ACCESS_KEY secret is missing or empty"
          exit 1
        fi
        if [ -n "$AWS_REGION" ]; then
          echo "✅ AWS_REGION secret exists"
        else
          echo "❌ AWS_REGION secret is missing or empty"
          exit 1
        fi
        if [ -n "$AWS_S3_BUCKET" ]; then
          echo "✅ AWS_S3_BUCKET secret exists"
        else
          echo "❌ AWS_S3_BUCKET secret is missing or empty"
          exit 1
        fi
      env:
        AWS_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
    
    - name: Set up AWS CLI credentials
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region ${{ secrets.AWS_REGION }}

    - name: Create archive of repository
      run: |
        REPO_NAME=$(echo "$GITHUB_REPOSITORY" | cut -d '/' -f 2)
        TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        ARCHIVE_NAME="${REPO_NAME}-${TIMESTAMP}.zip"
        git archive --format=zip --output="${ARCHIVE_NAME}" HEAD
        echo "ARCHIVE_NAME=${ARCHIVE_NAME}" >> $GITHUB_ENV
    
    - name: Verify and print S3 bucket name
      run: |
        echo "S3 Bucket: ${AWS_S3_BUCKET}"
        if [ -z "$AWS_S3_BUCKET" ]; then
          echo "❌ AWS_S3_BUCKET is empty"
          exit 1
        else
          echo "✅ AWS_S3_BUCKET is set correctly"
        fi
      env:
        AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
    
    - name: Upload to S3
      run: |
        echo "Uploading to s3://${AWS_S3_BUCKET}/${ARCHIVE_NAME}..."
        aws s3 cp "${ARCHIVE_NAME}" "s3://${AWS_S3_BUCKET}/${ARCHIVE_NAME}"
        echo "✅ Successfully uploaded ${ARCHIVE_NAME} to s3://${AWS_S3_BUCKET}/"
    
    - name: Create repository metadata file
      run: |
        REPO_NAME=$(echo "$GITHUB_REPOSITORY" | cut -d '/' -f 2)
        TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        METADATA_FILE="metadata-${TIMESTAMP}.json"
        
        echo '{' > $METADATA_FILE
        echo "  \"repository\": \"$GITHUB_REPOSITORY\"," >> $METADATA_FILE
        echo "  \"branch\": \"${GITHUB_REF#refs/heads/}\"," >> $METADATA_FILE
        echo "  \"commit\": \"$GITHUB_SHA\"," >> $METADATA_FILE
        echo "  \"archiveFile\": \"${ARCHIVE_NAME}\"," >> $METADATA_FILE
        echo "  \"migrationDate\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\"," >> $METADATA_FILE
        echo "  \"migrationBy\": \"$GITHUB_ACTOR\"" >> $METADATA_FILE
        echo '}' >> $METADATA_FILE
        
        aws s3 cp "${METADATA_FILE}" "s3://${AWS_S3_BUCKET}/${METADATA_FILE}"
        echo "✅ Successfully uploaded metadata to s3://${AWS_S3_BUCKET}/${METADATA_FILE}"
      env:
        AWS_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
